{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.dense1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.dense2 = keras.layers.Dense(10)\n",
    "        return \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = self.dense1(x)\n",
    "        output = self.dense2(x)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.1286947 ,  0.07764449,  0.35278645, -0.12542996, -0.11712442,\n",
       "         0.19695786,  0.23840117,  0.13067661,  0.15444487, -0.14986958],\n",
       "       [-0.10391721,  0.33540004,  0.25835368, -0.1754843 , -0.2553258 ,\n",
       "         0.12316856,  0.12006948,  0.1947205 ,  0.20065379, -0.10116769]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.random.uniform((2, 20))\n",
    "net = MLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 10), dtype=float32, numpy=\n",
       "array([[-0.06339863,  0.12825064, -0.08234776, -0.22646987, -0.18462273,\n",
       "        -0.10175624, -0.23564984, -0.2492517 ,  0.05311234,  0.30320397],\n",
       "       [ 0.05995935,  0.13287617,  0.21909091, -0.29701728, -0.12669116,\n",
       "        -0.10869291, -0.47255224, -0.259065  , -0.17982903,  0.17746148]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'), \n",
    "    keras.layers.Dense(10),\n",
    "])\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FancyMLP(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.constant_weight = tf.constant(\n",
    "            tf.random.uniform((20, 20))\n",
    "        )\n",
    "        self.dense = keras.layers.Dense(20, activation='relu')\n",
    "        return \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        x = self.flatten(inputs)\n",
    "        x = tf.nn.relu(tf.matmul(x, self.constant_weight) + 1)\n",
    "        x = self.dense(x)\n",
    "        while tf.norm(x) > 1:\n",
    "            x /= 2\n",
    "        if tf.norm(x) < 0.8:\n",
    "            x *= 10\n",
    "        return tf.reduce_sum(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=27.905592>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = FancyMLP()\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=23.448265>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class NestMLP(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = keras.Sequential([\n",
    "            keras.layers.Flatten(),\n",
    "            keras.layers.Dense(64, activation='relu'), \n",
    "            keras.layers.Dense(32, activation='relu'), \n",
    "        ])\n",
    "        self.dense = keras.layers.Dense(16, activation='relu')\n",
    "        return \n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.dense(self.net(inputs))\n",
    "\n",
    "\n",
    "net = keras.Sequential([\n",
    "    NestMLP(), \n",
    "    keras.layers.Dense(20), \n",
    "    FancyMLP()\n",
    "])\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
