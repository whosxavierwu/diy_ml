{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets as K_datasets\n",
    "from tensorflow.keras import models as K_models\n",
    "from tensorflow.keras import layers as K_layers\n",
    "from tensorflow.keras import utils as K_utils\n",
    "from tensorflow.keras import optimizers as K_optimizers\n",
    "from tensorflow.keras import backend as K_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 28, 28, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_0 (Conv2D)      (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_58 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_1 (Conv2D)      (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_59 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_2 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_60 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "encoder_conv_3 (Conv2D)      (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_61 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 2)                 6274      \n",
      "=================================================================\n",
      "Total params: 98,946\n",
      "Trainable params: 98,946\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"model_23\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3136)              9408      \n",
      "_________________________________________________________________\n",
      "reshape_7 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_0 (Conv2DTran (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_62 (LeakyReLU)   (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_1 (Conv2DTran (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_63 (LeakyReLU)   (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_2 (Conv2DTran (None, 28, 28, 32)        18464     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_64 (LeakyReLU)   (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_t_3 (Conv2DTran (None, 28, 28, 1)         289       \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 102,017\n",
      "Trainable params: 102,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "class Autoencoder:\n",
    "    def __init__(self, input_dim, encoder_conv_settings, decoder_conv_settings, z_dim):\n",
    "        self.input_dim=input_dim\n",
    "        self.encoder_conv_settings=encoder_conv_settings  # filters, kernel size, strides\n",
    "        self.decoder_conv_settings=decoder_conv_settings  # filters, kernel size, strides\n",
    "        self.z_dim=z_dim\n",
    "        self.model=None\n",
    "        return \n",
    "    \n",
    "    def build(self):\n",
    "        # Encoder\n",
    "        encoder_input = K_layers.Input(shape=self.input_dim, name='encoder_input')\n",
    "        x = encoder_input\n",
    "        for i, encoder_conv_setting in enumerate(self.encoder_conv_settings):\n",
    "            conv_layer = K_layers.Conv2D(\n",
    "                filters=encoder_conv_setting[0],\n",
    "                kernel_size=encoder_conv_setting[1],\n",
    "                strides=encoder_conv_setting[2],\n",
    "                padding='same',\n",
    "                name='encoder_conv_' + str(i)\n",
    "            )\n",
    "            x = conv_layer(x)\n",
    "            x = K_layers.LeakyReLU()(x)\n",
    "        shape_before_flatten = K_backend.int_shape(x)[1:]\n",
    "        x = K_layers.Flatten()(x)\n",
    "        encoder_output = K_layers.Dense(self.z_dim, name='encoder_output')(x)\n",
    "        \n",
    "        self.encoder = K_models.Model(encoder_input, encoder_output)\n",
    "        print(self.encoder.summary())\n",
    "        \n",
    "        # Decoder\n",
    "        decoder_input = K_layers.Input(shape=(self.z_dim, ), name='decoder_input')\n",
    "        x = K_layers.Dense(np.prod(shape_before_flatten))(decoder_input)\n",
    "        x = K_layers.Reshape(shape_before_flatten)(x)\n",
    "        for i, decoder_conv_setting in enumerate(self.decoder_conv_settings):\n",
    "            conv_t_layer = K_layers.Conv2DTranspose(\n",
    "                filters=decoder_conv_setting[0],\n",
    "                kernel_size=decoder_conv_setting[1],\n",
    "                strides=decoder_conv_setting[2],\n",
    "                padding='same',\n",
    "                name='decoder_conv_t_' + str(i)\n",
    "            )\n",
    "            x = conv_t_layer(x)\n",
    "            if i < len(self.decoder_conv_settings) - 1:\n",
    "                x = K_layers.LeakyReLU()(x)\n",
    "            else:\n",
    "                x = K_layers.Activation('sigmoid')(x)\n",
    "        decoder_output = x\n",
    "        \n",
    "        self.decoder = K_models.Model(decoder_input, decoder_output)\n",
    "        print(self.decoder.summary())\n",
    "        \n",
    "        # Full Autoencoder\n",
    "        self.model = K_models.Model(encoder_input, self.decoder(encoder_output))\n",
    "        return self.model\n",
    "    \n",
    "    def compile(self, learning_rate):\n",
    "        optimizer = K_optimizers.Adam(lr=learning_rate)\n",
    "        \n",
    "        def r_loss(y_true, y_pred):\n",
    "            return K_backend.mean(K_backend.square(y_true-y_pred), axis=[1,2,3])\n",
    "        \n",
    "        self.model.compile(optimizer=optimizer, loss=r_loss)\n",
    "        return\n",
    "    \n",
    "    def train(self, X_train, batch_size=32):\n",
    "        self.model.fit(\n",
    "            X_train, X_train, \n",
    "            batch_size=batch_size, \n",
    "            shuffle=True,\n",
    "            epochs=10\n",
    "        )\n",
    "        return \n",
    "    \n",
    "\n",
    "AE = Autoencoder(\n",
    "    input_dim=[28,28,1],\n",
    "    encoder_conv_settings=[\n",
    "        [32, 3, 1],\n",
    "        [64, 3, 2],\n",
    "        [64, 3, 2],\n",
    "        [64, 3, 1],\n",
    "    ],\n",
    "    decoder_conv_settings=[\n",
    "        [64, 3, 1],\n",
    "        [64, 3, 2],\n",
    "        [32, 3, 2],\n",
    "        [1,  3, 1],\n",
    "    ],\n",
    "    z_dim=2\n",
    ")\n",
    "model = AE.build()\n",
    "AE.compile(0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 9s 1us/step\n",
      "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "def load_mnist():\n",
    "    (x_train, y_train), (x_test, y_test) = K_datasets.mnist.load_data()\n",
    "\n",
    "    x_train = x_train.astype('float32') / 255.\n",
    "    x_train = x_train.reshape(x_train.shape + (1,))\n",
    "    x_test = x_test.astype('float32') / 255.\n",
    "    x_test = x_test.reshape(x_test.shape + (1,))\n",
    "\n",
    "    return (x_train, y_train), (x_test, y_test)\n",
    "(X_train, y_train), (X_test, y_test) = load_mnist()\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 98s 2ms/sample - loss: 0.0548\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 102s 2ms/sample - loss: 0.0460\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 108s 2ms/sample - loss: 0.0441\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 109s 2ms/sample - loss: 0.0431\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 110s 2ms/sample - loss: 0.0424\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 0.0419\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 0.0415\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 114s 2ms/sample - loss: 0.0411s - loss: 0.0\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 0.0408\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 111s 2ms/sample - loss: 0.0406\n"
     ]
    }
   ],
   "source": [
    "AE.train(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
