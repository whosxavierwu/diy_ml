{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xgboost \n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from pyhanlp import *\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors, TfidfModel\n",
    "from gensim.similarities import SparseMatrixSimilarity\n",
    "\n",
    "from WordVectorFetcher import WordVectorFetcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>content_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>[img]http://img.autohome.com.cn/album/smiles/s...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>“戏说”奔驰女再次向奔驰维权：要求赔偿240万--致广大网友的一封公开信广大支持过我的网友，...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>“这辆二手车多少钱买的?”因为家门口修车店维修工的这一句话，车主殷小姐憋了一肚子气，开着新买...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            content  content_id  \\\n",
       "0  negative  [img]http://img.autohome.com.cn/album/smiles/s...           0   \n",
       "1  negative  “戏说”奔驰女再次向奔驰维权：要求赔偿240万--致广大网友的一封公开信广大支持过我的网友，...           1   \n",
       "2  negative  “这辆二手车多少钱买的?”因为家门口修车店维修工的这一句话，车主殷小姐憋了一肚子气，开着新买...           2   \n",
       "\n",
       "   label_id  \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        -1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data \n",
    "df_data = pd.read_csv('data/sentiment_corpus_20191108.txt', encoding='utf8', sep='\\t', names=['label', 'content'])\n",
    "label2id = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "df_data['content_id'] = range(len(df_data))\n",
    "df_data['label_id'] = df_data['label'].apply(lambda x: label2id[x])\n",
    "print(df_data.shape)\n",
    "df_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading word vector file...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "class TfidfWordVectorCombiner:\n",
    "    def __init__(self):\n",
    "        self.dictionary = None\n",
    "        self.tfidf_model = None\n",
    "#         self.fetcher = WordVectorFetcher('tmp/sgns.sogou.word.bz2')\n",
    "        self.fetcher = WordVectorFetcher('tmp/sgns.zhihu.bigram-char.bz2')\n",
    "        print('Loading word vector file...')\n",
    "        self.fetcher.init()\n",
    "        print('Done')\n",
    "        self.NLPTokenizer = JClass(\"com.hankcs.hanlp.tokenizer.NLPTokenizer\")\n",
    "        \n",
    "    def seg(self, doc):\n",
    "        tokens = []\n",
    "        for item in self.NLPTokenizer.segment(doc):\n",
    "            word = item.word\n",
    "            tag = item.nature.toString()\n",
    "            # http://www.hankcs.com/nlp/part-of-speech-tagging.html#h2-8\n",
    "            if tag[0] not in ('w', 'x', 'y'):\n",
    "                tokens.append(word)\n",
    "        return tokens\n",
    "    \n",
    "    def fit(self, df_train):\n",
    "        corpus_train = list(df_train['content'].apply(self.seg))\n",
    "        self.dictionary = gensim.corpora.Dictionary(corpus_train)\n",
    "        corpus_train_bow = [self.dictionary.doc2bow(tokens) for tokens in corpus_train]\n",
    "        self.tfidf_model = TfidfModel(corpus_train_bow)\n",
    "        return\n",
    "\n",
    "    def transform(self, df):\n",
    "        corpus = list(df['content'].apply(self.seg))\n",
    "        corpus_bow = [self.dictionary.doc2bow(tokens) for tokens in corpus]\n",
    "        tfidf_corpus = [t for t in self.tfidf_model[corpus_bow]]\n",
    "        arr = []\n",
    "        for tfidf_doc in tfidf_corpus:\n",
    "            vec = np.zeros_like(self.fetcher.get_word_vector(u\"\"))\n",
    "            for token_id, token_tfidf in tfidf_doc:\n",
    "                token = self.dictionary[token_id]\n",
    "                vec += token_tfidf * self.fetcher.get_word_vector(token)\n",
    "            arr.append(vec.reshape((1, len(vec))))\n",
    "        X = np.concatenate(arr)\n",
    "        return X\n",
    "    \n",
    "    def fit_transform(self, df_train):\n",
    "        corpus_train = list(df_train['content'].apply(self.seg))\n",
    "        self.dictionary = gensim.corpora.Dictionary(corpus_train)\n",
    "        corpus_train_bow = [self.dictionary.doc2bow(tokens) for tokens in corpus_train]\n",
    "        self.tfidf_model = TfidfModel(corpus_train_bow)\n",
    "        \n",
    "        tfidf_corpus = [t for t in self.tfidf_model[corpus_train_bow]]\n",
    "        arr = []\n",
    "        for tfidf_doc in tfidf_corpus:\n",
    "            vec = np.zeros_like(self.fetcher.get_word_vector(u\"\"))\n",
    "            for token_id, token_tfidf in tfidf_doc:\n",
    "                token = self.dictionary[token_id]\n",
    "                vec += token_tfidf * self.fetcher.get_word_vector(token)\n",
    "            arr.append(vec.reshape((1, len(vec))))\n",
    "        X = np.concatenate(arr)\n",
    "        return X\n",
    "\n",
    "combiner = TfidfWordVectorCombiner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 4) (600, 4)\n",
      " 1    800\n",
      "-1    800\n",
      " 0    800\n",
      "Name: label_id, dtype: int64\n",
      " 0    200\n",
      " 1    200\n",
      "-1    200\n",
      "Name: label_id, dtype: int64\n",
      "(2400,) (600,)\n"
     ]
    }
   ],
   "source": [
    "### split dataset \n",
    "df_train, df_val = model_selection.train_test_split(\n",
    "    df_data, test_size=0.2, \n",
    "#     random_state=42, \n",
    "    shuffle=True, stratify=df_data['label_id']\n",
    ")\n",
    "print(df_train.shape, df_val.shape)\n",
    "\n",
    "print(df_train['label_id'].value_counts())\n",
    "print(df_val['label_id'].value_counts())\n",
    "\n",
    "y_train = df_train['label_id'].values\n",
    "y_val = df_val['label_id'].values\n",
    "print(y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 300) (600, 300)\n"
     ]
    }
   ],
   "source": [
    "X_train = combiner.fit_transform(df_train)\n",
    "X_val = combiner.transform(df_val)\n",
    "print(X_train.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=1, missing=None, n_estimators=500, n_jobs=-1,\n",
       "              nthread=None, objective='multi:softprob', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "              silent=None, subsample=1, verbosity=1)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = xgboost.XGBClassifier(n_estimators=500, n_jobs=-1)\n",
    "rf = RandomForestClassifier(n_estimators=500, n_jobs=-1)\n",
    "lr = LogisticRegression(n_jobs=-1, solver='lbfgs', multi_class='auto')\n",
    "svc = SVC(gamma='scale', kernel='rbf')\n",
    "\n",
    "model = xgb\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###### Train\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      1.00      1.00       800\n",
      "           0       1.00      1.00      1.00       800\n",
      "           1       1.00      1.00      1.00       800\n",
      "\n",
      "    accuracy                           1.00      2400\n",
      "   macro avg       1.00      1.00      1.00      2400\n",
      "weighted avg       1.00      1.00      1.00      2400\n",
      "\n",
      "###### Val\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.82      0.89      0.85       200\n",
      "           0       0.77      0.70      0.73       200\n",
      "           1       0.86      0.86      0.86       200\n",
      "\n",
      "    accuracy                           0.82       600\n",
      "   macro avg       0.82      0.82      0.82       600\n",
      "weighted avg       0.82      0.82      0.82       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "print('###### Train')\n",
    "print(metrics.classification_report(y_true=y_train, y_pred=y_train_pred))\n",
    "\n",
    "y_val_pred = model.predict(X_val)\n",
    "print('###### Val')\n",
    "print(metrics.classification_report(y_true=y_val, y_pred=y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.DataFrame([[u'这车不错'],[u'这车好！'], [u'这车不行啊']], columns=['content'])\n",
    "X_test = combiner.transform(df_test)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
