{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import xgboost \n",
    "from sklearn import model_selection\n",
    "\n",
    "import jieba\n",
    "from jieba import posseg\n",
    "from pyhanlp import *\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors, TfidfModel\n",
    "from gensim.similarities import SparseMatrixSimilarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>content_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "      <td>[img]http://img.autohome.com.cn/album/smiles/s...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>“戏说”奔驰女再次向奔驰维权：要求赔偿240万--致广大网友的一封公开信广大支持过我的网友，...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "      <td>“这辆二手车多少钱买的?”因为家门口修车店维修工的这一句话，车主殷小姐憋了一肚子气，开着新买...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                            content  content_id  \\\n",
       "0  negative  [img]http://img.autohome.com.cn/album/smiles/s...           0   \n",
       "1  negative  “戏说”奔驰女再次向奔驰维权：要求赔偿240万--致广大网友的一封公开信广大支持过我的网友，...           1   \n",
       "2  negative  “这辆二手车多少钱买的?”因为家门口修车店维修工的这一句话，车主殷小姐憋了一肚子气，开着新买...           2   \n",
       "\n",
       "   label_id  \n",
       "0        -1  \n",
       "1        -1  \n",
       "2        -1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### load data \n",
    "df_data = pd.read_csv('data/sentiment_corpus_20191108.txt', encoding='utf8', sep='\\t', names=['label', 'content'])\n",
    "label2id = {'negative': -1, 'neutral': 0, 'positive': 1}\n",
    "df_data['content_id'] = range(len(df_data))\n",
    "df_data['label_id'] = df_data['label'].apply(lambda x: label2id[x])\n",
    "print(df_data.shape)\n",
    "df_data[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 4) (600, 4)\n",
      " 1    800\n",
      "-1    800\n",
      " 0    800\n",
      "Name: label_id, dtype: int64\n",
      "-1    200\n",
      " 1    200\n",
      " 0    200\n",
      "Name: label_id, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "### split dataset \n",
    "df_train, df_val = model_selection.train_test_split(\n",
    "    df_data, test_size=0.2, \n",
    "    random_state=42, shuffle=True, stratify=df_data['label_id']\n",
    ")\n",
    "print(df_train.shape, df_val.shape)\n",
    "print(df_train['label_id'].value_counts())\n",
    "print(df_val['label_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>content</th>\n",
       "      <th>content_id</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2108</td>\n",
       "      <td>positive</td>\n",
       "      <td>。中东V97抢购天津夏季进口三菱帕杰罗外型设计新帕杰罗的外型突出了其开发的主题思想-即“面向...</td>\n",
       "      <td>2108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>444</td>\n",
       "      <td>negative</td>\n",
       "      <td>偶的F2T958怠速开空调有时也有哒哒声，不过是有规律的响，一阵一阵的，偶试过别的车也有如富...</td>\n",
       "      <td>444</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>514</td>\n",
       "      <td>negative</td>\n",
       "      <td>上下班市区里开，原来首选是1.8T，但看了不少帖子后，对1.8T的故障越看越害怕，2.0T要...</td>\n",
       "      <td>514</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         label                                            content  content_id  \\\n",
       "2108  positive  。中东V97抢购天津夏季进口三菱帕杰罗外型设计新帕杰罗的外型突出了其开发的主题思想-即“面向...        2108   \n",
       "444   negative  偶的F2T958怠速开空调有时也有哒哒声，不过是有规律的响，一阵一阵的，偶试过别的车也有如富...         444   \n",
       "514   negative  上下班市区里开，原来首选是1.8T，但看了不少帖子后，对1.8T的故障越看越害怕，2.0T要...         514   \n",
       "\n",
       "      label_id  \n",
       "2108         1  \n",
       "444         -1  \n",
       "514         -1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### segmentation tokenize\n",
    "df_train[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLPTokenizer = JClass(\"com.hankcs.hanlp.tokenizer.NLPTokenizer\")\n",
    "# print(NLPTokenizer.segment(\"我新造一个词叫幻想乡你能识别并正确标注词性吗？\"))  # “正确”是副形词。\n",
    "# # 注意观察下面两个“希望”的词性、两个“晚霞”的词性\n",
    "# print(NLPTokenizer.analyze(\"我的希望是希望张晚霞的背影被晚霞映红\").translateLabels())\n",
    "# print(NLPTokenizer.analyze(\"支援臺灣正體香港繁體：微软公司於1975年由比爾·蓋茲和保羅·艾倫創立。\"))\n",
    "\n",
    "def seg(doc):\n",
    "    tokens = []\n",
    "#     for word, tag in posseg.cut(doc):\n",
    "#         if tag not in ['x']:\n",
    "#             tokens.append(word)\n",
    "    for item in NLPTokenizer.segment(doc):\n",
    "        word = item.word\n",
    "        tag = item.nature.toString()\n",
    "        # http://www.hankcs.com/nlp/part-of-speech-tagging.html#h2-8\n",
    "        if tag[0] not in ('w', 'x', 'y'):\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(77213 unique tokens: ['1%', '17694994877', '184', '18802221755', '2']...)\n"
     ]
    }
   ],
   "source": [
    "corpus = list(df_train['content'].apply(seg))\n",
    "dictionary = gensim.corpora.Dictionary(corpus)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_bow = [dictionary.doc2bow(tokens) for tokens in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfModel(corpus_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tfidf[dictionary.doc2bow(corpus[1])]\n",
    "# tfidf[dictionary.doc2bow(seg(df_val['content'].values[1]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index = SparseMatrixSimilarity(tfidf[corpus_bow[:10]], num_features=12)\n",
    "# index[tfidf[dictionary.doc2bow(seg(df_val['content'].values[1]))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVectorFetcher:\n",
    "    def __init__(self, filename):\n",
    "        self.wv_filename = filename\n",
    "        self.wv = None\n",
    "\n",
    "    def init(self):\n",
    "        self.wv = KeyedVectors.load_word2vec_format(self.wv_filename)\n",
    "\n",
    "    def get_word_vector(self, word):\n",
    "        if word not in self.wv:\n",
    "            return np.zeros(self.wv.vector_size)\n",
    "        else:\n",
    "            return self.wv[word]\n",
    "\n",
    "    def get_sentence_vector(self, sentence):\n",
    "        words = [item.word for item in HanLP.segment(sentence)]\n",
    "        cnt = 0\n",
    "        vec_fin = np.zeros(self.wv.vector_size)\n",
    "        for w in words:\n",
    "            if w in self.wv:\n",
    "                vec_fin += self.get_word_vector(w)\n",
    "                cnt += 1\n",
    "        if cnt > 0:\n",
    "            vec_fin = vec_fin / cnt\n",
    "        return vec_fin\n",
    "\n",
    "    def get_sentence_similarity(self, s1, s2):\n",
    "        v1 = self.get_sentence_vector(s1)\n",
    "        v2 = self.get_sentence_vector(s2)\n",
    "        return self.wv.cosine_similarities(v1, [v2])\n",
    "        # return self.wv.wmdistance(s1, s2)\n",
    "\n",
    "fn = 'data/sgns.sogou.word.bz2'\n",
    "fetcher = WordVectorFetcher(fn)\n",
    "fetcher.init()\n",
    "# wv1 = fetcher.get_sentence_vector(u'今天天气算不错的了')\n",
    "# wv2 = fetcher.get_sentence_vector(u'今天没下雨')\n",
    "print(fetcher.get_sentence_similarity(u'今天天气算不错的了', u'今天在北京没下雨'))\n",
    "print(fetcher.get_sentence_similarity(u'车头大面积进气格栅用镀铬材质进行装饰后年轻化效果显著', u'同时，在车头两侧，还有LED光源的头灯进行加持，夜间点亮后辨识度也很高'))\n",
    "print(fetcher.get_sentence_similarity(u'方向盘低速灵活高速平稳，就算18寸的大脚跑高速120都稳稳得一点都不飘', u'在路上不放音乐听发动机声音很平顺，高速过弯车身倾斜也很小，高速120会有风噪声'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetcher.get_sentence_vector(df_val['content'].values[0])\n",
    "# todo sen_vec * tfidf ==> 300d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### training "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
